<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.16"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>EAGLE ZYBO Linux: Presentation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/SVG"],
});
</script><script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">EAGLE ZYBO Linux
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.16 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_Presentation.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Presentation </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Things to brag about</h2>
<h3>Baremetal</h3>
<p>We have completely re-written the original C code for the drone controller. We're using a <b>modern GCC toolchain</b>, instead of the outdated version that came with the Xilinx SDK. Using modern <b>C++</b> allowed us to write much <b>cleaner, easier to read code with fewer bugs</b>. The most important bug fix was the <b>sensor system</b>. Large mathematical errors were not seen by the authors, which caused the measurement orientation to drift. Now, the IMU calibration and AHRS update are mathematically correct, and the system is equipped with a beefy Madgwick sensor-fusion filter, so <b>there is absolutely no drift</b>. Furthermore, many small bugs from the original code have been fixed, and <b>extra structure and functionality</b> has been added. The structure of the code has been improved in the several ways.</p>
<ul>
<li><b>DOCUMENTATION!!! For the love of god...</b>.</li>
<li><b>NO MORE GLOBALS BEING WRITTEN &amp; READ ALL OVER THE CODE!</b> The flow of data can clearly be followed in <em>MainInterrupt.cpp</em>.</li>
<li><b>Separation of src-vivado/ and src/</b>. The first directory contains code to start the Xilinx platform, read from inputs (IMU/AHRS, RC, SONAR) and write to outputs (BUZZER, MOTORS, WPT).</li>
<li><b>Class representation</b> of the three controllers (ATTITUDE, ALTITUDE, POSITION);</li>
<li><b>Clear distinction between controllers flight modes</b> (MANUAL, ALTITUDE-HOLD, AUTONOMOUS).</li>
<li>Struct representation of input measurements, control system types and output signals;<ul>
<li><b>Autonomous-FSM</b> using the states IDLE_GROUND, PRE_TAKEOFF, TAKEOFF, LOITERING, NAVIGATING, CONVERGING, LANDING, WPT and ERROR. If autonomous mode is started during flight, then the drone will begin in the LOITERING state. Otherwise, it will begin in the IDLE_GROUND state.</li>
</ul>
</li>
<li><b>QR-FSM</b> to facilitate the communication between ANC, IMP and CRYPTO when decrypting <a class="el" href="structQR.html">QR</a> codes. This includes the states IDLE, QR_READ_REQUEST, QR_READ_BUSY, NEW_TARGET, QR_LAND, QR_UNKNOWN, and ERROR.</li>
</ul>
<p>Some aspects of the assignment have been extended. Firstly, during altitude-hold mode, the pilot is able to adjust the reference height with the RC throttle. A more significant change is the <b>rework of the autonomous mode</b>. Aside from switching to autonomous mode after stable altitude-hold flight, <b>the pilot now has the option to start this mode from the ground</b>. If the drone is grounded and in autonomous mode, then the pilot can start autonomous flight by raising the RC throttle. The drone will perform a pre-takeoff routine (ESC script for example), and then <b>it will take off autonomously</b>. As soon as it reaches the reference height, it will begin loitering. After that, it will follow the <a class="el" href="structQR.html">QR</a> trail and automatically land. The pilot can then flip the WPT switch to power the LED wall.</p>
<p>In addition, many extra functionalites have been added to the framework.</p>
<ul>
<li><b>Adjustable IMU configuration</b>. The frequency of the IMU, and therefore the entire framework, can be set to 119, 238, 476 or 952 Hz. The resolution of the IMU can also be adjusted: the maximum value of the gyroscope can be set to 245, 500 or 2000 deg/s, and that of the accelerometer can be set to 2, 4, 8, or 16 g.</li>
<li>The drone comes equipped with <b>five controller configurations</b>. Using the tuner knob, the pilot can change the controller configuration without having to reboot the Zybo. This allows for rapid testing of various parameters and <b>calibration of the ESCs</b>, which is set to configuration 5.</li>
<li>If the hardware team requires special PWM signals or timings to start properly, the framework is provided to add a <b>custom ESC startup script</b>.</li>
<li><b>Gradual thrust change</b> prevents rapid thrust change when switching from altitude- hold mode to manual mode, or when the ESC startup script has finished and the drone assumes the thrust provided by the RC.</li>
<li>The <b>buzzer</b> now plays sounds for initiation, arming, disarming, controller configuration, Autonomous/QR error states (TODO) and WPT (TODO).</li>
</ul>
<p>// TODO: created or used? \ We used a complete cross-compilation toolchain with a cross-platform build system, so we can develop and run unit tests on our computer.</p>
<p>We have done <b>performance checks</b> on the new and old programs, and we can confirm that after switching to C++, our program still runs at exactly the same speed, and the increase in readability and maintainability is huge. The rework has even allowed us to run the IMU at 952 Hz instead of 238 Hz. This resulted in a better orientation estimate and a more stable control system.</p>
<p>The <b>controller code is automatically generated</b> using a MATLAB script, and the boot image can be immediately copied to the drone using <code>SCP</code>. Then the Zybo is rebooted over <code>SSH</code>. Before doing this, we had to unplug the battery, remove the SD card, run to a computer, copy the new boot image, run back to the drone, insert the SD card, plug in the battery, wait for the Zybo to boot and finally wait for the WiFi router to boot (5 minutes). <b>This has improved our process flow so much</b>.</p>
<h3>Vision</h3>
<p>The first approach used the Hough transform in OpenCV Python. However, this was too slow, so the algorithm skipped some squares when moving or tilting too fast. A second approach just counted the number of red pixels on each row and each column. This was a bit faster, but it only worked if the drone didn't rotate about the z-axis. This algorithm still occasionally skipped a square, making it not suitable for a loitering controller. We tried speeding things up even more by down-sampling the images, but no avail.</p>
<p>Another problem for vision was the given Python framework. It had some serious issues, such as deadlock between the vision and logger thread, it didn't release the video input when something went wrong, and it degraded the performance even further.</p>
<p>After countless nights of trying to get the drone to loiter, we decided to start from scratch. We threw out the Python framework in favor of a much more light-weight C++ application, and we created a very ingenious grid finder algorithm in C++ as well.</p>
<p>For development of the vision algorithm on the PC, we used <a class="el" href="namespacepybind11.html">pybind11</a>. This allowed us to use our C++ algorithm in Jupyter notebooks in Python, having access to all the benefits of a scripting language, and modules like matplotlib and OpenCV for easy debugging, while still keeping super fast C++ performance.</p>
<p>Once we had the algorithm figured out, and we could show it working on the given videos, we started setting up a cross-compilation toolchain for the ZYBO. <br  />
We decided to use a Docker build container, so it could be used by all team members, regardless of the operating system they were using. The toolchain consists of a custom GCC build for the ZYBO, with cross-compiled versions of the OpenCV and ZBar libraries. Native x86 versions of all tools are available as well, so we can do the initial development on the computer, without requiring access to the ZYBO. <br  />
All unit tests (that don't require platform-specific features like the FPGA) are run natively in the Docker container as well. <br  />
The entire toolchain is tightly integrated with Visual Studio Code: there are shortcuts for quickly building the entire project for ARM or for x86, for running the unit test on the PC or on the ZYBO, for getting a shell on the ZYBO, for starting a debug session on the ZYBO, etc. <br  />
CMake ensures that all libraries and binaries are up to date, and they are automatically synced with the drone over SSH. <br  />
For unit testing, the Google Test framework is used. Automatic documentation generation is handled by Doxygen. A Python Jupyter environment and Python bindings for the C++ libraries we wrote are available as well, for easy visualization of the vision algorithm. All of this is contained within the Docker container.</p>
<p>Once we got our grid finder algorithm working on the ZYBO, it became clear that we had to speed up the masking as well: the new algorithm to find the lines ran at 800 fps, but the masking (detecting the red pixels in the image) only ran at 50 fps. We got rid of the OpenCV functions for masking, and wrote our own version in C++. We're using the ARM <a class="el" href="namespaceNEON.html">NEON</a> SIMD vector unit of the ZYBO, using intrinsics, meaning that we can mask 16 pixels in parallel. At the full resolution of 640×480, the masking now runs at almost 1000 fps.</p>
<p>All of this means that we're able to update the position measurement of the drone at 60 fps, which is the refresh rate of the HDMI input. This enables us to design better controllers, and ensures that we don't skip any squares, even when moving very quickly.</p>
<p>The grid finder algorithm is very robust. It can handle cases where certain parts are overexposed by direct sunlight, gaps in the lines, curved lines due to lens distortion, and it is mathematically correct even when turning the drone 360° around the z-axis.</p>
<p><b>Video sunlight</b> <br  />
 
<video width=1600 controls>
  <source src="drone-images-sunlight+mask.mp4" type="video/mp4">
</video>
 <b>Video 360°</b> <br  />
 
<video width=1600 controls>
  <source src="DroneCam-Spinning.mp4" type="video/mp4">
</video>
</p>
<p>The final Linux application consists of three main parts: the vision algorithm for the localization, the <a class="el" href="structQR.html">QR</a> decoding using ZBar and the algorithm developed by our crypto team, that runs on the FPGA, and the data logger for ANC.</p>
<p>Decoding the <a class="el" href="structQR.html">QR</a> code happens asynchronously, so it doesn't interrupt the vision algorithm (it does slow it down slightly). The logger doesn't really require any processing, it just reads whatever it finds in the shared memory from ANC, and sends it over the network as UDP Multicast. It runs in a separate thread, and runs periodically. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.16 </li>
  </ul>
</div>
</body>
</html>
